{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt7ZS1_wGgjn"
      },
      "outputs": [],
      "source": [
        "#installing the corret pyspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9yAbVymmEIp"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark-ai langchain"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C3x0ZRLxjMVr"
      },
      "source": [
        "Set Environment Variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdOOq4twHN1K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"fill in\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ACYMwhgHTYz",
        "outputId": "1495d1f1-2bfe-4f1e-d3ef-099d8136e009"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "KR1zLBk1998Z",
        "outputId": "823d56e0-66d9-4623-d187-e636533b5bb8"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdR8Nj865ZRv"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from pyspark_ai import SparkAI\n",
        "\n",
        "# If 'gpt-4' is unavailable, use 'gpt-3.5-turbo' (might lower output quality)\n",
        "llm = ChatOpenAI(model_name='gpt-4', temperature=0)\n",
        "# Initialize SparkAI with the ChatOpenAI model\n",
        "spark_ai = SparkAI(llm=llm, verbose=True)\n",
        "\n",
        "spark_ai.activate()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O-lj_uQGxUIE"
      },
      "source": [
        "## Read Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJsP643y5mLw"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType, DoubleType\n",
        "\n",
        "schema = StructType([ \\\n",
        "    StructField('longitude',StringType(),True), \\\n",
        "    StructField('latitude',StringType(),True), \\\n",
        "    StructField('housing_median_age',StringType(),True), \\\n",
        "    StructField('total_rooms', StringType(), True), \\\n",
        "    StructField('total_bedrooms', StringType(), True), \\\n",
        "    StructField('population', DoubleType(), True), \\\n",
        "    StructField('households', StringType(), True),\\\n",
        "    StructField('median_income', StringType(), True),\\\n",
        "    StructField('median_house_value', StringType(), True)\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tivst737BZo-"
      },
      "outputs": [],
      "source": [
        "df = spark.read.option(\"header\",\"true\").csv('sample_data/california_housing_test.csv',schema=schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6oVnt9_By9p",
        "outputId": "8139a043-b4c0-4eea-f5a2-c4af3f9ac27a"
      },
      "outputs": [],
      "source": [
        "df.schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Usw_lKzpYGg",
        "outputId": "7885a885-8cca-40d1-df5d-b89ce2ddfe47"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "RdrRAE_y5iSF",
        "outputId": "0707a637-9d80-4f19-fb70-df5e7d8a34ae"
      },
      "outputs": [],
      "source": [
        "df.ai.verify(\"expect housing median age to be above 0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHSf0LYbrTGe"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "def check_housing_median_age(df) -> bool:\n",
        "\n",
        "    # Check if all values in 'housing_median_age' column are above 0\n",
        "    if df.filter(col('housing_median_age') <= 0).count() > 0:\n",
        "        return False\n",
        "    else:\n",
        "        return True"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1FSRItrvyjZi"
      },
      "source": [
        "## Create UDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmTcExK_rXv0",
        "outputId": "be04aaba-c071-46bb-c906-40292484564b"
      },
      "outputs": [],
      "source": [
        "@spark_ai.udf\n",
        "def convert_population(population: float) -> str:\n",
        "    \"\"\"Convert the population to a three bucket tiers\"\"\"\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1FjLTo2y8jR"
      },
      "outputs": [],
      "source": [
        "def convert_population(population) -> str:\n",
        "    if population is not None:\n",
        "        if population < 100:\n",
        "            return 'small'\n",
        "        elif 100 <= population < 500:\n",
        "            return 'medium'\n",
        "        else:\n",
        "            return 'large'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLzquG2tzZLa",
        "outputId": "3ae05b43-7688-44f3-bca8-11965484a227"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "convert_populationUDF = udf(lambda z:convert_population(z),StringType())\n",
        "\n",
        "df.withColumn(\"population tier\", convert_populationUDF(col(\"population\"))) \\\n",
        "  .show(truncate=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gj7V5FKf0rQr"
      },
      "source": [
        "## Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2esCg6eMJua3",
        "outputId": "566a0c66-e4f0-4a25-fe7c-42ff28cf7d53"
      },
      "outputs": [],
      "source": [
        "top_10_house_value = df.ai.transform(\"find me the top 10 location with the highest median house value\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "7rJGq9QZKhv_",
        "outputId": "085fe583-a328-4651-819b-776c52f65784"
      },
      "outputs": [],
      "source": [
        "top_10_house_value.ai.explain()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mmnfui5sLDd7",
        "outputId": "ba42572e-6f13-4278-d60c-40dc0bf931df"
      },
      "outputs": [],
      "source": [
        "top_10_house_value.ai.plot(\"bar with no grid and background white; x value is location; y value is median home value\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-W5dsNXI0bFQ"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8QZ6G6EwH98B",
        "outputId": "39b18d4c-53ab-4955-e6d1-4442769e7d78"
      },
      "outputs": [],
      "source": [
        "df.ai.plot(\"histogram of the median house value\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1sFImdwnvY3a",
        "outputId": "4d0d01fa-e87d-46b5-faa8-61e0b28073a5"
      },
      "outputs": [],
      "source": [
        "df.ai.plot(\"histogram of the median house value into 20 buckets with no grid and background white\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
